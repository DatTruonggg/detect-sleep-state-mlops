{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ MLflow Tracking URI: http://localhost:5001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 50.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/weight/random_forest.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(min_samples_leaf=300, n_estimators=200, n_jobs=-1,\n",
      "                       random_state=67)\n",
      "âœ… Model 'Random_forest' version 1 loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "import joblib\n",
    "# Thiáº¿t láº­p MLflow Tracking URI\n",
    "mlflow_tracking_uri = \"http://localhost:5001\"  # DÃ¹ng tÃªn service cá»§a MLflow trong Docker\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# Kiá»ƒm tra xem MLflow Tracking Server cÃ³ nháº­n URI Ä‘Ãºng khÃ´ng\n",
    "print(f\"ðŸ”¥ MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Khá»Ÿi táº¡o MLflow Client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Láº¥y version má»›i nháº¥t cá»§a model \"Random_forest\" theo cÃ¡c stage [\"None\", \"Production\", \"Staging\"]\n",
    "# Láº¥y version theo alias \"current\"\n",
    "model_version_info = client.get_model_version_by_alias(\"Random_forest\", \"Staging\")\n",
    "model_version = model_version_info.version\n",
    "\n",
    "# Táº¡o URI Ä‘á»ƒ táº£i model\n",
    "model_uri = f\"models:/Random_forest/{model_version}\"\n",
    "\n",
    "# Load model\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "print(model)\n",
    "model = joblib.load(f\".{model}\")\n",
    "print(model)\n",
    "print(f\"âœ… Model 'Random_forest' version {model_version} loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (121980175.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mlflow models list --filter \"name='Random_forest'\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.api.types import is_datetime64_ns_dtype\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/raw/Generated_Test_Data.csv\")\n",
    "test.to_parquet(\"../data/raw/Generated_Test_Data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"../data/raw/train_series.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = train[train[\"step\"] == 592375]\n",
    "print(train_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    \n",
    "    df['series_id'] = df['series_id'].astype('category')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n",
    "    df['hour'] = df[\"timestamp\"].dt.hour\n",
    "    \n",
    "    df.sort_values(['timestamp'], inplace=True)\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    df['lids'] = np.maximum(0., df['enmo'] - 0.02)\n",
    "    df['lids'] = df['lids'].rolling(f'{120*5}s', center=True, min_periods=1).agg('sum')\n",
    "    df['lids'] = 100 / (df['lids'] + 1)\n",
    "    df['lids'] = df['lids'].rolling(f'{360*5}s', center=True, min_periods=1).agg('mean').astype(np.float32)\n",
    "    \n",
    "    df[\"enmo\"] = (df[\"enmo\"]*1000).astype(np.int16)\n",
    "    df[\"anglez\"] = df[\"anglez\"].astype(np.int16)\n",
    "    df[\"anglezdiffabs\"] = df[\"anglez\"].diff().abs().astype(np.float32)\n",
    "    \n",
    "    for col in ['enmo', 'anglez', 'anglezdiffabs']:\n",
    "        \n",
    "        # periods in seconds        \n",
    "        periods = [60, 360, 720, 3600] \n",
    "        \n",
    "        for n in periods:\n",
    "            \n",
    "            rol_args = {'window':f'{n+5}s', 'min_periods':10, 'center':True}\n",
    "            \n",
    "            for agg in ['median', 'mean', 'max', 'min', 'var']:\n",
    "                df[f'{col}_{agg}_{n}'] = df[col].rolling(**rol_args).agg(agg).astype(np.float32).values\n",
    "                gc.collect()\n",
    "            \n",
    "            if n == max(periods):\n",
    "                df[f'{col}_mad_{n}'] = (df[col] - df[f'{col}_median_{n}']).abs().rolling(**rol_args).median().astype(np.float32)\n",
    "            \n",
    "            df[f'{col}_amplit_{n}'] = df[f'{col}_max_{n}']-df[f'{col}_min_{n}']\n",
    "            df[f'{col}_amplit_{n}_min'] = df[f'{col}_amplit_{n}'].rolling(**rol_args).min().astype(np.float32).values\n",
    "            \n",
    "#             if col in ['enmo', 'anglez']:\n",
    "            df[f'{col}_diff_{n}_max'] = df[f'{col}_max_{n}'].diff().abs().rolling(**rol_args).max().astype(np.float32)\n",
    "            df[f'{col}_diff_{n}_mean'] = df[f'{col}_max_{n}'].diff().abs().rolling(**rol_args).mean().astype(np.float32)\n",
    "\n",
    "    \n",
    "            gc.collect()\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"../data/processed/merged_data.parquet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng_by_id(idx):\n",
    "    \n",
    "    from warnings import simplefilter \n",
    "    simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "    \n",
    "    df  = pd.read_parquet(file, filters=[('series_id','=',idx)])\n",
    "    df['event'] = df['event'].astype(np.int8)\n",
    "    df = feat_eng(df)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = False\n",
    "\n",
    "series_id  = pd.read_parquet(file, columns=['series_id'])\n",
    "series_id = series_id.series_id.unique()\n",
    "\n",
    "print(len(series_id))\n",
    "\n",
    "if DEV:\n",
    "    series_id = series_id[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = Parallel(n_jobs=6)(delayed(feat_eng_by_id)(i) for i in series_id)\n",
    "train = pd.concat(train, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDUCE train data by half\n",
    "step=400 if DEV else 60\n",
    "train = train.iloc[::step]\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['series_id', 'step', 'timestamp']\n",
    "\n",
    "X, y = train.drop(columns=drop_cols+['event']), train['event']\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DEV:\n",
    "    del train\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleAvgProba():\n",
    "    \n",
    "    def __init__(self, classifiers):\n",
    "        \n",
    "        self.classifiers = classifiers\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        for classifier in self.classifiers:                \n",
    "            classifier.fit(X, y)\n",
    "            gc.collect()\n",
    "     \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        probs = []\n",
    "        \n",
    "        for m in self.classifiers:\n",
    "            probs.append(m.predict_proba(X))\n",
    "        \n",
    "        probabilities = np.stack(probs)\n",
    "        p = np.mean(probabilities, axis=0)\n",
    "        \n",
    "        return p \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        probs = []\n",
    "        \n",
    "        for m in self.classifiers:\n",
    "            probs.append(m.predict(X))\n",
    "        \n",
    "        probabilities = np.stack(probs)\n",
    "        p = np.mean(probabilities, axis=0)\n",
    "        \n",
    "        return p.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "lgb_params1 = {    \n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.03,\n",
    "    'n_estimators': 1,\n",
    "    'subsample_for_bin': 200000,\n",
    "    'min_child_weight': 0.001,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,  # Uncommented this line\n",
    "    'reg_alpha': 0.05,\n",
    "    'reg_lambda': 0.05,\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 1,\n",
    "    'objective': \"binary:logistic\",\n",
    "    'learning_rate': 0.02,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 2,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 6,\n",
    "    'random_state': 42,\n",
    "    'verbose': 0  # to prevent training output, remove or set to a larger value to see training progress\n",
    "}\n",
    "\n",
    "model = EnsembleAvgProba(classifiers=[\n",
    "    lgb.LGBMClassifier(random_state=42, **lgb_params1),\n",
    "    GradientBoostingClassifier(n_estimators=1, max_depth=5, min_samples_leaf=300, random_state=42),\n",
    "    RandomForestClassifier(n_estimators=1, min_samples_leaf=300, random_state=42, n_jobs=-1),\n",
    "    xgb.XGBClassifier(**xgb_params),\n",
    "    CatBoostClassifier(**cat_params),\n",
    "    ExtraTreesClassifier(n_estimators=1, min_samples_leaf=300, random_state=42, n_jobs=-1)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(idx, classifier, file='test_series.parquet') :\n",
    "    \n",
    "    test  = pd.read_parquet(f'../data/raw/{file}',\n",
    "                    filters=[('series_id','=',idx)])\n",
    "    test = feat_eng(test)\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    test = test[drop_cols]\n",
    "\n",
    "    preds, probs = classifier.predict(X_test), classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    test['prediction'] = preds\n",
    "    test['prediction'] = test['prediction'].rolling(360+1, center=True).median()\n",
    "    test['probability'] = probs\n",
    "    \n",
    "    test = test[test['prediction']!=2]\n",
    "    \n",
    "    test.loc[test['prediction']==0, 'probability'] = 1-test.loc[test['prediction']==0, 'probability']\n",
    "    test['score'] = test['probability'].rolling(60*12*5, center=True, min_periods=10).mean().bfill().ffill()\n",
    "\n",
    "    \n",
    "    test['pred_diff'] = test['prediction'].diff()\n",
    "    \n",
    "    test['event'] = test['pred_diff'].replace({1:'wakeup', -1:'onset', 0:np.nan})\n",
    "    \n",
    "    test_wakeup = test[test['event']=='wakeup'].groupby(test['timestamp'].dt.date).agg('first')\n",
    "    test_onset = test[test['event']=='onset'].groupby(test['timestamp'].dt.date).agg('last')\n",
    "    test = pd.concat([test_wakeup, test_onset], ignore_index=True).sort_values('timestamp')\n",
    "\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_sub = ['series_id','step','event','score']\n",
    "\n",
    "series_id  = pd.read_parquet('../data/raw/test_series.parquet', columns=['series_id'])\n",
    "series_id = series_id.series_id.unique()\n",
    "\n",
    "tests = []\n",
    "\n",
    "for idx in series_id: \n",
    "\n",
    "    test = get_events(idx, model)\n",
    "    tests.append(test[cols_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat(tests, ignore_index=True).reset_index(names='row_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
